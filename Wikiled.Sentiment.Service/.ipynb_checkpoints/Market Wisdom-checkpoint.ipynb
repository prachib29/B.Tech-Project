{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\Desktop\\New folder\\BtechProjSmallRes\\src\n"
     ]
    }
   ],
   "source": [
    "cd /home/prachi/Wikiled.Sentiment.Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:29:59,535 - utilities - INFO - Found 0 type with 366 records\n",
      "2020-10-31 14:29:59,539 - utilities - INFO - Found 1 type with 384 records\n",
      "2020-10-31 14:29:59,540 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:00,560 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:30:00,563 - learning - INFO - 0.676\n",
      "2020-10-31 14:30:00,563 - learning - INFO - {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:30:00,565 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:30:00,567 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:01,044 - utilities - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.682     0.608     0.643       120\n",
      "           1      0.671     0.738     0.703       130\n",
      "\n",
      "    accuracy                          0.676       250\n",
      "   macro avg      0.677     0.673     0.673       250\n",
      "weighted avg      0.677     0.676     0.674       250\n",
      "\n",
      "2020-10-31 14:30:01,048 - utilities - INFO - Macro F1 0.673\n",
      "2020-10-31 14:30:01,052 - utilities - INFO - Micro F1 0.676\n",
      "2020-10-31 14:30:17,690 - utilities - INFO - Found 0 type with 366 records\n",
      "2020-10-31 14:30:17,694 - utilities - INFO - Found 1 type with 384 records\n",
      "2020-10-31 14:30:17,695 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:18,851 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:30:18,853 - learning - INFO - 0.688\n",
      "2020-10-31 14:30:18,854 - learning - INFO - {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:30:18,857 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:30:18,858 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:19,198 - utilities - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.675     0.642     0.658       120\n",
      "           1      0.684     0.715     0.699       130\n",
      "\n",
      "    accuracy                          0.680       250\n",
      "   macro avg      0.680     0.679     0.679       250\n",
      "weighted avg      0.680     0.680     0.680       250\n",
      "\n",
      "2020-10-31 14:30:19,202 - utilities - INFO - Macro F1 0.679\n",
      "2020-10-31 14:30:19,205 - utilities - INFO - Micro F1 0.680\n",
      "2020-10-31 14:30:36,264 - utilities - INFO - Found 0 type with 366 records\n",
      "2020-10-31 14:30:36,268 - utilities - INFO - Found 1 type with 384 records\n",
      "2020-10-31 14:30:36,269 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:37,323 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:30:37,324 - learning - INFO - 0.6293333333333333\n",
      "2020-10-31 14:30:37,325 - learning - INFO - {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:30:37,327 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:30:37,328 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:37,752 - utilities - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.649     0.525     0.581       120\n",
      "           1      0.627     0.738     0.678       130\n",
      "\n",
      "    accuracy                          0.636       250\n",
      "   macro avg      0.638     0.632     0.630       250\n",
      "weighted avg      0.638     0.636     0.632       250\n",
      "\n",
      "2020-10-31 14:30:37,755 - utilities - INFO - Macro F1 0.630\n",
      "2020-10-31 14:30:37,757 - utilities - INFO - Micro F1 0.636\n",
      "2020-10-31 14:30:54,462 - utilities - INFO - Found 0 type with 366 records\n",
      "2020-10-31 14:30:54,465 - utilities - INFO - Found 1 type with 384 records\n",
      "2020-10-31 14:30:54,466 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:55,646 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:30:55,647 - learning - INFO - 0.5933333333333334\n",
      "2020-10-31 14:30:55,649 - learning - INFO - {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "2020-10-31 14:30:55,651 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:30:55,653 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:30:56,159 - utilities - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.577     0.533     0.554       120\n",
      "           1      0.597     0.638     0.617       130\n",
      "\n",
      "    accuracy                          0.588       250\n",
      "   macro avg      0.587     0.586     0.586       250\n",
      "weighted avg      0.587     0.588     0.587       250\n",
      "\n",
      "2020-10-31 14:30:56,161 - utilities - INFO - Macro F1 0.586\n",
      "2020-10-31 14:30:56,164 - utilities - INFO - Micro F1 0.588\n"
     ]
    }
   ],
   "source": [
    "import logging.config\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import quandl\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras import Sequential, callbacks\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from DataLoader import DataLoader\n",
    "from MarketData import QuandlMarketDataSource, RedditMarketDataSource, BloombergMarketDataSource\n",
    "\n",
    "from learning.BasicLearning import RbfClassifier\n",
    "from utilities import Constants\n",
    "from utilities.Utilities import Utilities\n",
    "\n",
    "logging.config.fileConfig('logging.conf', disable_existing_loggers=False)\n",
    "quandl.ApiConfig.api_key = '__YOUR_KEY__'\n",
    "\n",
    "\n",
    "def build_model(inputs, model_type):\n",
    "\n",
    "    model = Sequential()\n",
    "    if model_type == 'Basic_LSTM':\n",
    "        model.add(LSTM(400, input_shape=(inputs.shape[1], inputs.shape[2]), return_sequences=False))\n",
    "        model.add(Dropout(0.5))\n",
    "    elif model_type == 'Conv':\n",
    "        model.add(LSTM(200, input_shape=(inputs.shape[1], inputs.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(LSTM(100,\n",
    "                       return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(400, input_shape=(inputs.shape[1], inputs.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(LSTM(400, return_sequences=False))\n",
    "        model.add(Dropout(0.3))\n",
    "    else:\n",
    "        raise ValueError(model_type)\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_data(full_articles, sentiment_location, price_source, stock):\n",
    "    loader = DataLoader()\n",
    "    if price_source == 'quandl':\n",
    "        source = QuandlMarketDataSource()\n",
    "    elif price_source == 'reddit':\n",
    "        source = RedditMarketDataSource()\n",
    "    else:\n",
    "        source = BloombergMarketDataSource()\n",
    "    x_data, y_data = loader.load_data(stock, 5,\n",
    "                                      source=source,\n",
    "                                      sentiment_location=sentiment_location,\n",
    "                                      full_articles=full_articles,\n",
    "                                      from_date='2011-04-01', to_date='2015-04-01')\n",
    "#     pd.DataFrame(x_data).to_csv(\"x_data.csv\")\n",
    "#     pd.DataFrame(y_data).to_csv(\"y_data.csv\")\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(x_data)\n",
    "    x_data = scaler.transform(x_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def lstm_prediction(model_type, x_train, x_test, y_train):\n",
    "\n",
    "    y_train = Utilities.make_dual(y_train, 2)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    # initialise model architecture\n",
    "    market_model = build_model(x_train, model_type)\n",
    "    market_model.summary()\n",
    "    # train model on data\n",
    "    # note: eth_history contains information on the training error per epoch\n",
    "    cbks = [callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "    market_model.fit(x_train, y_train, batch_size=1000, callbacks=cbks, epochs=50, validation_split=0.25, shuffle=True)\n",
    "    y_result_prob = market_model.predict(x_test)\n",
    "#     print(y_result_prob[:100])\n",
    "    y_result = Utilities.make_single_dimension(y_result_prob)\n",
    "    return y_result, y_result_prob\n",
    "\n",
    "\n",
    "def svm_prediction(x_train, x_test, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ['clf', RbfClassifier()]])\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_result = pipeline.predict(x_test)\n",
    "    y_result_prob = pipeline.predict_proba(x_test)\n",
    "    np.save(r\".\\x_train_classifiers18.npy\", x_train)\n",
    "    np.save(r\".\\x_test_classifiers18.npy\", x_test)\n",
    "    np.save(r\".\\y_train_classifiers18.npy\", y_train)\n",
    "\n",
    "    return y_result, y_result_prob\n",
    "\n",
    "\n",
    "def processing(price_source, stock, load_articles, full_articles, processing_type='SVM'):\n",
    "\n",
    "    x_data, y_data = get_data(full_articles, load_articles, price_source, stock)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
    "\n",
    "    if processing_type == 'SVM':\n",
    "        y_result, y_result_prob = svm_prediction(x_train, x_test, y_train)\n",
    "        np.save(r\".\\y_test_classifiers18.npy\", y_test)\n",
    "\n",
    "    else:\n",
    "        y_result, y_result_prob = lstm_prediction(processing_type, x_train, x_test, y_train)\n",
    "        \n",
    "    Utilities.measure_performance(y_test, y_result)\n",
    "    Utilities.measure_performance_auc(y_test, y_result, y_result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    item = 'HPQ'\n",
    "    price_source = 'quandl'\n",
    "    processing_type = 'SVM'\n",
    "    sentiment_location = path.join(Constants.DATASETS_MARKET, 'Twitter/psenti.csv')\n",
    "#     technical analysis\n",
    "    processing(price_source, item, None, False, processing_type)\n",
    "#     # technical analysis + Sentiment\n",
    "    sentiment_location = path.join(Constants.DATASETS_MARKET, 'FinArticles/psenti/all.results.csv')\n",
    "    processing(price_source, item, sentiment_location, False, processing_type)\n",
    "    sentiment_location = path.join(Constants.DATASETS_MARKET, 'FinArticles/psenti/reddit.results.csv')\n",
    "    processing(price_source, item, sentiment_location, False, processing_type)\n",
    "    # technical analysis + Sentiment + Mood\n",
    "    processing(price_source, item, sentiment_location, True, processing_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:15:00,820 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:15:39,647 - utilities - INFO - Found 0 type with 338 records\n",
      "2020-10-31 14:15:39,672 - utilities - INFO - Found 1 type with 412 records\n",
      "2020-10-31 14:15:39,674 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:15:46,577 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:15:46,579 - learning - INFO - 0.6666666666666666\n",
      "2020-10-31 14:15:46,581 - learning - INFO - {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:15:46,582 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:15:46,890 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:15:58,040 - utilities - INFO - Found 0 type with 338 records\n",
      "2020-10-31 14:15:58,044 - utilities - INFO - Found 1 type with 412 records\n",
      "2020-10-31 14:15:58,045 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:15:59,042 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:15:59,045 - learning - INFO - 0.668\n",
      "2020-10-31 14:15:59,047 - learning - INFO - {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:15:59,050 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:15:59,053 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:16:09,679 - utilities - INFO - Found 0 type with 338 records\n",
      "2020-10-31 14:16:09,684 - utilities - INFO - Found 1 type with 412 records\n",
      "2020-10-31 14:16:09,684 - learning - INFO - Searching classifier best parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 14:16:10,917 - learning - INFO - Best parameters found:\n",
      "2020-10-31 14:16:10,920 - learning - INFO - 0.6693333333333333\n",
      "2020-10-31 14:16:10,921 - learning - INFO - {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "2020-10-31 14:16:10,923 - learning - INFO - Creating calibrated...\n",
      "2020-10-31 14:16:10,926 - learning - INFO - Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\aman\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n",
      "For lookback 2\n",
      "For lookback 3\n",
      "For lookback 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5fc33861f3af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;31m#             print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;31m#             print(\"Technical analysis\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessing_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             \u001b[1;31m# technical analysis + Sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;31m#             print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5fc33861f3af>\u001b[0m in \u001b[0;36mprocessing\u001b[1;34m(price_source, stock, load_articles, full_articles, processing_type, look_back)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mx_test1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_for_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"For lookback\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0my_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_result_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0my_test1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;31m#     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\y_test_lstm.npy\", y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5fc33861f3af>\u001b[0m in \u001b[0;36mlstm_prediction\u001b[1;34m(model_type, x_train, x_test, y_train, look_back)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;31m#     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\x_test_lstm.npy\", x_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;31m#     market_model.fit(x_train, y_train, batch_size=1000, callbacks=cbks, epochs=50, validation_split=0.25, shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mmarket_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0my_result_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarket_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Trying on LSTM\n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "auc = []\n",
    "import logging.config\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import quandl\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras import Sequential, callbacks\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from DataLoader import DataLoader\n",
    "from MarketData import QuandlMarketDataSource, RedditMarketDataSource, BloombergMarketDataSource\n",
    "import tensorflow as tf\n",
    "from learning.BasicLearning import RbfClassifier\n",
    "from utilities import Constants\n",
    "from utilities.Utilities import Utilities\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "logging.config.fileConfig('logging.conf', disable_existing_loggers=False)\n",
    "quandl.ApiConfig.api_key = '__YOUR_KEY__'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def data_for_lstm(look_back, dataset):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back+1):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def model_select(model_type):\n",
    "    if(model_type == \"RandomForestClassifier\"):\n",
    "        pipeline = RandomForestClassifier()\n",
    "    elif(model_type == \"LogisticRegression\"):\n",
    "        pipeline = LogisticRegression()\n",
    "    elif(model_type == \"ExtraTreesClassifier\"):\n",
    "        pipeline = ExtraTreesClassifier()\n",
    "    elif(model_type == \"BaggingClassifier\"):\n",
    "        pipeline = BaggingClassifier()\n",
    "    elif(model_type == \"DecisionTreeClassifier\"):\n",
    "        pipeline = DecisionTreeClassifier()\n",
    "    elif(model_type == \"AdaBoostClassifier\"):\n",
    "        pipeline = AdaBoostClassifier()\n",
    "    elif(model_type == 'SVM'):\n",
    "        pipeline = Pipeline([['clf', RbfClassifier()]])\n",
    "    else:\n",
    "        raise ValueError(model_type)\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def build_model(inputs, model_type):\n",
    "\n",
    "    model = Sequential()\n",
    "    if model_type == 'Basic_LSTM':\n",
    "        model.add(LSTM(4,  input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "#         model.add(Dropout(0.5))\n",
    "    elif model_type == 'Conv':\n",
    "        model.add(LSTM(200, input_shape=(inputs.shape[1], inputs.shape[2]), return_sequences=True, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(LSTM(100,\n",
    "                       return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(400, input_shape=(inputs.shape[1], inputs.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(LSTM(400, return_sequences=False))\n",
    "        model.add(Dropout(0.3))\n",
    "    else:\n",
    "        raise ValueError(model_type)\n",
    "\n",
    "    model.add(Dense(1))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_data(full_articles, sentiment_location, price_source, stock):\n",
    "    loader = DataLoader()\n",
    "    if price_source == 'quandl':\n",
    "        source = QuandlMarketDataSource()\n",
    "    elif price_source == 'reddit':\n",
    "        source = RedditMarketDataSource()\n",
    "    else:\n",
    "        source = BloombergMarketDataSource()\n",
    "    x_data, y_data = loader.load_data(stock, 5,\n",
    "                                      source=source,\n",
    "                                      sentiment_location=sentiment_location,\n",
    "                                      full_articles=full_articles,\n",
    "                                      from_date='2011-04-01', to_date='2015-04-01')\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(x_data)\n",
    "    x_data = scaler.transform(x_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def lstm_prediction(model_type, x_train, x_test, y_train, look_back):\n",
    "    \n",
    "    lookback = look_back\n",
    "#     y_train = Utilities.make_dual(y_train, 2)\n",
    "#     x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "#     x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    # initialise model architecture\n",
    "    market_model = build_model(x_train, model_type)\n",
    "#     print(x_train[:100])\n",
    "#     market_model.summary()\n",
    "    # train model on data\n",
    "    # note: eth_history contains information on the training error per epoch\n",
    "    cbks = [callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "#     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\x_train_lstm.npy\", x_train)\n",
    "#     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\y_train_lstm.npy\", y_train)\n",
    "#     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\x_test_lstm.npy\", x_test)\n",
    "#     market_model.fit(x_train, y_train, batch_size=1000, callbacks=cbks, epochs=50, validation_split=0.25, shuffle=True)\n",
    "    market_model.fit(x_train, y_train, epochs=50, validation_split=0.25, shuffle=True, verbose = 0, callbacks = cbks)\n",
    "\n",
    "    y_result_prob = market_model.predict(x_test)\n",
    "    y_result = Utilities.make_single_dimension(y_result_prob)\n",
    "    return y_result, y_result_prob\n",
    "\n",
    "\n",
    "def model_prediction(x_train, x_test, y_train, pipeline):\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_result = pipeline.predict(x_test)\n",
    "    y_result_prob = pipeline.predict_proba(x_test)\n",
    "    return y_result, y_result_prob\n",
    "\n",
    "\n",
    "def processing(price_source, stock, load_articles, full_articles, processing_type='SVM', look_back = 5):\n",
    "\n",
    "    x_data, y_data = get_data(full_articles, load_articles, price_source, stock)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
    "\n",
    "    if processing_type in non_sequential_models:\n",
    "        pipeline = model_select(processing_type)\n",
    "        y_result, y_result_prob = model_prediction(x_train, x_test, y_train, pipeline)\n",
    "#         Utilities.measure_performance(y_test, y_result)\n",
    "        accuracy1, auc_score1, f1_score1= Utilities.measure_performance_auc(y_test, y_result, y_result)\n",
    "        acc.append(accuracy1)\n",
    "        f1.append(f1_score1)\n",
    "        auc.append(auc_score1)\n",
    "    else:\n",
    "        look_backs = [2,3,5]\n",
    "        for look_back in look_backs:\n",
    "            y_train1 = y_train[look_back-1:]\n",
    "            x_train1 = data_for_lstm(look_back, x_train)\n",
    "            x_test1 = data_for_lstm(look_back, x_test)     \n",
    "            print(\"For lookback\", look_back)\n",
    "            y_result, y_result_prob = lstm_prediction(processing_type, x_train1, x_test1, y_train1, look_back)\n",
    "            y_test1 = y_test[look_back-1:]\n",
    "    #     np.save(r\"C:\\Users\\aman\\Desktop\\Btech Project\\src\\y_test_lstm.npy\", y_test)\n",
    "    #     print(y_result[:100])\n",
    "    #     print(y_test[:100])\n",
    "    #     print(y_result_prob[:100])\n",
    "#             Utilities.measure_performance(y_test1, y_result)\n",
    "            accuracy1, auc_score1, f1_score1= Utilities.measure_performance_auc(y_test1, y_result, y_result)\n",
    "            acc.append(accuracy1)\n",
    "            f1.append(f1_score1)\n",
    "            auc.append(auc_score1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = ['JPM', 'HPQ', 'GOOG', 'AAPL']\n",
    "    price_source = 'quandl'\n",
    "    processing_types = [\"RandomForestClassifier\",'SVM', 'LogisticRegression', 'ExtraTreesClassifier','BaggingClassifier','DecisionTreeClassifier','AdaBoostClassifier','Basic_LSTM','Conv',\"LSTM\" ]\n",
    "    non_sequential_models = [\"RandomForestClassifier\",'SVM', 'LogisticRegression', 'ExtraTreesClassifier','BaggingClassifier','DecisionTreeClassifier','AdaBoostClassifier' ]\n",
    "    sequential_models = ['Basic_LSTM','Conv',\"LSTM\"]\n",
    "    for item in items:\n",
    "        for processing_type in processing_types:\n",
    "#             print(item)\n",
    "#             print(price_source)\n",
    "#             print(processing_type)\n",
    "            path =  '/Twitter/' + 'results' + item + '.csv'\n",
    "            sentiment_location = Constants.DATASETS_MARKET + path\n",
    "            # technical analysis\n",
    "#             print()\n",
    "#             print(\"Technical analysis\")\n",
    "            processing(price_source, item, None, False, processing_type)\n",
    "            # technical analysis + Sentiment\n",
    "#             print()\n",
    "#             print(\"technical analysis + Sentiment\")\n",
    "            processing(price_source, item, sentiment_location, False, processing_type)\n",
    "            # technical analysis + Sentiment + Mood\n",
    "#             print()\n",
    "#             print(\"technical analysis + Sentiment + Mood\")\n",
    "            processing(price_source, item, sentiment_location, True, processing_type)\n",
    "#             print()\n",
    "#             print()\n",
    "#             print()\n",
    "        print(item, len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
